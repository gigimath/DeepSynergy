{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization Script\n",
    "\n",
    "Author: Kristina Preuer\n",
    "\n",
    "This script shows how the data was split and how the features were normalized. The data is then saved in a pickle file. Which will be loaded during the cross validation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the parameters for data generation: folds for testing and validation and normalization strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define nomalization function\n",
    "It normalizes the input data X. If X is used for training the mean and the standard deviation is calculated during normalization. If X is used for validation or testing, the previously calculated mean and standard deviation of the training data should be used. If \"tanh_norm\" is used as normalization strategy, then the mean and standard deviation are calculated twice. The features with a standard deviation of 0 are filtered out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A2058', 'A2780', 'A375', 'A427', 'CAOV3', 'COLO320DM', 'DLD1', 'EFM192B', 'ES2', 'HCT116', 'HT144', 'HT29', 'KPL1', 'LNCAP', 'LOVO', 'MDAMB436', 'MSTO', 'NCIH1650', 'NCIH2122', 'NCIH23', 'NCIH460', 'NCIH520', 'OCUBM', 'OV90', 'OVCAR3', 'PA1', 'RKO', 'RPMI7951', 'SKMEL30', 'SKMES1', 'SKOV3', 'SW620', 'SW837', 'T47D', 'UACC62', 'UWB1289BRCA1', 'UWB1289', 'VCAP', 'ZR751'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data'+os.sep+'dict_cl2features.pkl', 'rb') as pk:\n",
    "    dict_cl2features = pickle.load(pk)\n",
    "dict_cl2features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['5-FU', 'ABT-888', 'AZD1775', 'BEZ-235', 'BORTEZOMIB', 'CARBOPLATIN', 'CYCLOPHOSPHAMIDE', 'DASATINIB', 'DEXAMETHASONE', 'DINACICLIB', 'DOXORUBICIN', 'ERLOTINIB', 'ETOPOSIDE', 'GELDANAMYCIN', 'GEMCITABINE', 'L778123', 'LAPATINIB', 'METFORMIN', 'METHOTREXATE', 'MITOMYCINE', 'MK-2206', 'MK-4541', 'MK-4827', 'MK-5108', 'MK-8669', 'MRK-003', 'OXALIPLATIN', 'PACLITAXEL', 'PD325901', 'SN-38', 'SORAFENIB', 'SUNITINIB', 'TEMOZOLOMIDE', 'TOPOTECAN', 'VINBLASTINE', 'VINORELBINE', 'ZOLINZA', 'MK-8776'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data'+os.sep+'dict_drug2features.pkl', 'rb') as pk:\n",
    "    dict_drug2features = pickle.load(pk)\n",
    "dict_drug2features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26752\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug_a_name</th>\n",
       "      <th>drug_b_name</th>\n",
       "      <th>cell_line</th>\n",
       "      <th>synergy</th>\n",
       "      <th>fold</th>\n",
       "      <th>fold_random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5-FU</td>\n",
       "      <td>DINACICLIB</td>\n",
       "      <td>A2058</td>\n",
       "      <td>4.331695</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5-FU</td>\n",
       "      <td>MK-8669</td>\n",
       "      <td>A2058</td>\n",
       "      <td>32.336232</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5-FU</td>\n",
       "      <td>PD325901</td>\n",
       "      <td>A2058</td>\n",
       "      <td>2.264835</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5-FU</td>\n",
       "      <td>AZD1775</td>\n",
       "      <td>A2058</td>\n",
       "      <td>13.052687</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5-FU</td>\n",
       "      <td>BEZ-235</td>\n",
       "      <td>A2058</td>\n",
       "      <td>13.679112</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  drug_a_name drug_b_name cell_line    synergy  fold  fold_random\n",
       "0        5-FU  DINACICLIB     A2058   4.331695     0            0\n",
       "1        5-FU     MK-8669     A2058  32.336232     0            2\n",
       "2        5-FU    PD325901     A2058   2.264835     0            1\n",
       "4        5-FU     AZD1775     A2058  13.052687     1            1\n",
       "5        5-FU     BEZ-235     A2058  13.679112     1            4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#contains synergy values and fold split (numbers 0-4)\n",
    "labels = pd.read_csv('data'+os.sep+'CSV3_cv5folds_cvrandom_concat_regression.csv', index_col=0)\n",
    "print(len(labels))\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for da, db, cl, s, f1, f2 in labels.values:\n",
    "    X.append(np.concatenate((dict_drug2features[da],dict_drug2features[db],dict_cl2features[cl])))\n",
    "    \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26752, 12758)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalization function"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "XX = X[idx_tr]\n",
    "print(XX.shape)\n",
    "\n",
    "std1 = np.nanstd(XX, axis=0)\n",
    "print(std1.shape)\n",
    "\n",
    "feat_filt = std1!=0\n",
    "print(feat_filt.shape)\n",
    "X2 = XX[:,feat_filt]\n",
    "print(X2.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feat_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X, means1=None, std1=None, means2=None, std2=None, feat_filt=None, norm='tanh_norm'):\n",
    "    if std1 is None:\n",
    "        std1 = np.nanstd(X, axis=0)\n",
    "    if feat_filt is None:\n",
    "        feat_filt = std1!=0\n",
    "        #print(X.shape)\n",
    "    X = X[:,feat_filt]\n",
    "    #print(X.shape)\n",
    "    X = np.ascontiguousarray(X)\n",
    "    #print(X.shape)\n",
    "    if means1 is None:\n",
    "        means1 = np.mean(X, axis=0)\n",
    "    X = (X-means1)/std1[feat_filt]\n",
    "    if norm == 'norm':\n",
    "        return(X, means1, std1, feat_filt)\n",
    "    elif norm == 'tanh':\n",
    "        return(np.tanh(X), means1, std1, feat_filt)\n",
    "    elif norm == 'tanh_norm':\n",
    "        X = np.tanh(X)\n",
    "        if means2 is None:\n",
    "            means2 = np.mean(X, axis=0)\n",
    "        if std2 is None:\n",
    "            std2 = np.std(X, axis=0)\n",
    "        X = (X-means2)/std2\n",
    "        X[:,std2==0]=0\n",
    "        return(X, means1, std1, means2, std2, feat_filt)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_tr, mean, std, mean2, std2, feat_filt = normalize(X_tr, norm=norm)\n",
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define indices for splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fold = 4\n",
    "val_fold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices of training data for hyperparameter selection: fold 2, 3, 4\n",
    "idx_tr = np.where(np.logical_and(labels['fold_random']!=test_fold, labels['fold_random']!=val_fold))\n",
    "#indices of validation data for hyperparameter selection: fold 1\n",
    "idx_val = np.where(labels['fold_random']==val_fold)\n",
    "\n",
    "\n",
    "#indices of training data for model testing: fold 1, 2, 3, 4\n",
    "idx_train = np.where(labels['fold_random']!=test_fold)\n",
    "#indices of test data for model testing: fold 0\n",
    "idx_test = np.where(labels['fold_random']==test_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X[idx_tr]\n",
    "X_val = X[idx_val]\n",
    "X_train = X[idx_train]\n",
    "X_test = X[idx_test]\n",
    "\n",
    "y_tr = labels.iloc[idx_tr]['synergy'].values\n",
    "y_val = labels.iloc[idx_val]['synergy'].values\n",
    "y_train = labels.iloc[idx_train]['synergy'].values\n",
    "y_test = labels.iloc[idx_test]['synergy'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16050, 12758) (5342, 12758)\n",
      "(21392, 12758) (5360, 12758)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape, X_val.shape)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize training and validation data for hyperparameter selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize training and test data for methods comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 'tanh_norm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16050, 8466) (5342, 8466)\n",
      "(21392, 8466) (5360, 8466)\n"
     ]
    }
   ],
   "source": [
    "if norm == \"tanh_norm\":\n",
    "    X_tr, mean, std, mean2, std2, feat_filt = normalize(X_tr, norm=norm)\n",
    "    X_val, mean, std, mean2, std2, feat_filt = normalize(X_val, mean, std, mean2, std2, feat_filt=feat_filt, norm=norm)\n",
    "else:\n",
    "    X_tr, mean, std, feat_filt = normalize(X_tr, norm=norm)\n",
    "    X_val, mean, std, feat_filt = normalize(X_val, mean, std, feat_filt=feat_filt, norm=norm)\n",
    "    \n",
    "print(X_tr.shape, X_val.shape)\n",
    "\n",
    "if norm == \"tanh_norm\":\n",
    "    X_train, mean, std, mean2, std2, feat_filt = normalize(X_train, norm=norm, feat_filt=feat_filt)\n",
    "    X_test, mean, std, mean2, std2, feat_filt = normalize(X_test, mean, std, mean2, std2, feat_filt=feat_filt, norm=norm)\n",
    "else:\n",
    "    X_train, mean, std, feat_filt = normalize(X_train, norm=norm)\n",
    "    X_test, mean, std, feat_filt = normalize(X_test, mean, std, feat_filt=feat_filt, norm=norm)\n",
    "    \n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data as pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_data_cv = 'data_cv'+os.sep\n",
    "pickle.dump((X_tr, X_val, X_train, X_test, y_tr, y_val, y_train, y_test), \n",
    "            open(path_data_cv+'data_test_fold%d_%s.p'%(test_fold, norm), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
